{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST training with MXNet and Gluon\n",
    "\n",
    "MNIST is a widely used dataset for handwritten digit classification. It consists of 70,000 labeled 28x28 pixel grayscale images of hand-written digits. The dataset is split into 60,000 training images and 10,000 test images. There are 10 classes (one for each of the 10 digits). This tutorial will show how to train and test an MNIST model on SageMaker using MXNet and the Gluon API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.mxnet import MXNet\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "output_path='s3://' + sess.default_bucket() + '/mxnet/mnist'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MXNet Estimator\n",
    "\n",
    "The `MXNet` class allows you to run your training script on SageMaker\n",
    "infrastracture in a containerized environment. In this notebook, we will\n",
    "refer to this container as *training container*. \n",
    "\n",
    "You need to configure\n",
    "it with the following parameters to set up the environment:\n",
    "\n",
    "- entry_point: A user defined python file to be used by the training container as the \n",
    "instructions for training. We will further discuss this file in the next subsection.\n",
    "\n",
    "- role: An IAM role to make AWS service requests\n",
    "\n",
    "- instance_type: The type of SageMaker instance to run your training script. \n",
    "Set it to `local` if you want to run the training job on \n",
    "the SageMaker instance you are using to run this notebook\n",
    "\n",
    "- instance count: The number of instances you need to run your training job. \n",
    "Multiple instances are needed for distributed training.\n",
    "\n",
    "- output_path: \n",
    "S3 location to save training output (model artifacts and output files)\n",
    "\n",
    "- framework_version: The version of MXNet you need to use.\n",
    "\n",
    "- py_version: The python version you need to use\n",
    "\n",
    "For more information, see [the API reference](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html#sagemaker.estimator.EstimatorBase)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the entry point for training\n",
    "\n",
    "The entry point for training is a python script that provides all \n",
    "the code for training a MXNet model. It is used by the SageMaker \n",
    "MXNet Estimator (`MXNet` class above) as the entry point for running the training job.\n",
    "\n",
    "Under the hood, SageMaker MXNet Estimator downloads a docker image\n",
    "with runtime environemnts \n",
    "specified by the parameters you used to initiated the\n",
    "estimator class and it injects the training script into the \n",
    "docker image to be used as the entry point to run the container.\n",
    "\n",
    "In the rest of the notebook, we use *training image* to refer to the \n",
    "docker image specified by the MXNet Estimator and *training container*\n",
    "to refer to the container that runs the training image. \n",
    "\n",
    "This means your training script is very similar to a training script\n",
    "you might run outside Amazon SageMaker, but it can access the useful environment \n",
    "variables provided by the training image. Checkout [the short list of environment variables provided by the SageMaker service](https://sagemaker.readthedocs.io/en/stable/frameworks/mxnet/using_mxnet.html?highlight=entry%20point) to see some common environment \n",
    "variables you might used. Checkout [the complete list of environment variables](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md) for a complete \n",
    "description of all environment variables your training script\n",
    "can access to. \n",
    "\n",
    "In this example, we will use the training script `code/train.py`\n",
    "as the entry point for our MXNet Estimator.\n",
    "\n",
    "The script here is an adaptation of the [Gluon MNIST example](https://github.com/apache/incubator-mxnet/blob/master/example/gluon/mnist.py) provided by the [Apache MXNet](https://mxnet.incubator.apache.org/) project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mgzip\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mmx\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m gluon, autograd\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mgluon\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m nn\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmxnet\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mgluon\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Dataset\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "logging.basicConfig(level=logging.DEBUG)\r\n",
      "\r\n",
      "\u001b[37m# ------------------------------------------------------------ #\u001b[39;49;00m\r\n",
      "\u001b[37m# Training methods                                             #\u001b[39;49;00m\r\n",
      "\u001b[37m# ------------------------------------------------------------ #\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_transformer\u001b[39;49;00m(data, label):\r\n",
      "    data = data.reshape((-\u001b[34m1\u001b[39;49;00m,)).astype(np.float32) / \u001b[34m255.\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m data, label\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mMNIST\u001b[39;49;00m(Dataset):\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, data_dir, train=\u001b[34mTrue\u001b[39;49;00m, transform=\u001b[34mNone\u001b[39;49;00m):\r\n",
      "\r\n",
      "        \u001b[34mif\u001b[39;49;00m train:\r\n",
      "            images_file=\u001b[33m\"\u001b[39;49;00m\u001b[33mtrain-images-idx3-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "            labels_file=\u001b[33m\"\u001b[39;49;00m\u001b[33mtrain-labels-idx1-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "        \u001b[34melse\u001b[39;49;00m:\r\n",
      "            images_files=\u001b[33m\"\u001b[39;49;00m\u001b[33mt10k-images-idx3-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "            labels_files=\u001b[33m\"\u001b[39;49;00m\u001b[33mt10k-labels-idx1-ubyte.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\r\n",
      "        \r\n",
      "        \u001b[36mself\u001b[39;49;00m.images, \u001b[36mself\u001b[39;49;00m.labels = \u001b[36mself\u001b[39;49;00m._convert_to_numpy(\r\n",
      "                data_dir, images_file, labels_file)\r\n",
      "\r\n",
      "        \u001b[34mdef\u001b[39;49;00m \u001b[32m_id\u001b[39;49;00m(x, y):\r\n",
      "            \u001b[34mreturn\u001b[39;49;00m x, y\r\n",
      "        \u001b[36mself\u001b[39;49;00m.transform = transform \u001b[35mor\u001b[39;49;00m _id \r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__len__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.labels)\r\n",
      "    \r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m__getitem__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, idx):\r\n",
      "        img, label = \u001b[36mself\u001b[39;49;00m.images[idx], \u001b[36mself\u001b[39;49;00m.labels[idx]\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.transform(img, label)\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32m_convert_to_numpy\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, data_dir, images_file, labels_file):\r\n",
      "        \u001b[33m\"\"\"Byte string to numpy arrays \u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \u001b[34mwith\u001b[39;49;00m gzip.open(os.path.join(data_dir, images_file), \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "            images = np.frombuffer(f.read(), \r\n",
      "                    np.uint8, offset=\u001b[34m16\u001b[39;49;00m).reshape(-\u001b[34m1\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m, \u001b[34m28\u001b[39;49;00m)\r\n",
      "\r\n",
      "        \u001b[34mwith\u001b[39;49;00m gzip.open(os.path.join(data_dir, labels_file), \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\r\n",
      "            labels = np.frombuffer(f.read(), np.uint8, offset=\u001b[34m8\u001b[39;49;00m)\r\n",
      "\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m (images, labels)\r\n",
      "    \r\n",
      "    \r\n",
      "    \r\n",
      "    \r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mget_data_loader\u001b[39;49;00m(data_dir, batch_size, train=\u001b[34mTrue\u001b[39;49;00m):\r\n",
      "    mnist = MNIST(data_dir, train, input_transformer)\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m gluon.data.DataLoader(mnist, batch_size=batch_size,\r\n",
      "            shuffle=\u001b[34mTrue\u001b[39;49;00m, last_batch=\u001b[33m'\u001b[39;49;00m\u001b[33mrollover\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(args):\r\n",
      "    \u001b[37m# SageMaker passes num_cpus, num_gpus and other args we can use to tailor training to\u001b[39;49;00m\r\n",
      "    \u001b[37m# the current container environment, but here we just use simple cpu context.\u001b[39;49;00m\r\n",
      "    ctx = mx.cpu()\r\n",
      "\r\n",
      "    \u001b[37m# retrieve the hyperparameters we set in notebook (with some defaults)\u001b[39;49;00m\r\n",
      "    batch_size = args.batch_size\r\n",
      "    epochs = args.epochs\r\n",
      "    learning_rate = args.learning_rate\r\n",
      "    momentum = args.momentum\r\n",
      "    log_interval = args.log_interval\r\n",
      "\r\n",
      "    num_gpus = \u001b[36mint\u001b[39;49;00m(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    current_host = args.current_host\r\n",
      "    hosts = args.hosts\r\n",
      "    model_dir = args.model_dir\r\n",
      "    CHECKPOINTS_DIR = \u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/checkpoints\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    checkpoints_enabled = os.path.exists(CHECKPOINTS_DIR)\r\n",
      "\r\n",
      "    \u001b[37m# load training and validation data\u001b[39;49;00m\r\n",
      "    \u001b[37m# we use the gluon.data.vision.MNIST class because of its built in mnist pre-processing logic,\u001b[39;49;00m\r\n",
      "    \u001b[37m# but point it at the location where SageMaker placed the data files, so it doesn't download them again.\u001b[39;49;00m\r\n",
      "   \r\n",
      "    train_data = get_data_loader(args.train, batch_size)\r\n",
      "    val_data = get_data_loader(args.test, batch_size)\r\n",
      "\r\n",
      "    \u001b[37m# define the network\u001b[39;49;00m\r\n",
      "    net = define_network()\r\n",
      "\r\n",
      "    \u001b[37m# Collect all parameters from net and its children, then initialize them.\u001b[39;49;00m\r\n",
      "    net.initialize(mx.init.Xavier(magnitude=\u001b[34m2.24\u001b[39;49;00m), ctx=ctx)\r\n",
      "    \u001b[37m# Trainer is for updating parameters with gradient.\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(hosts) == \u001b[34m1\u001b[39;49;00m:\r\n",
      "        kvstore = \u001b[33m'\u001b[39;49;00m\u001b[33mdevice\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m num_gpus > \u001b[34m0\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mlocal\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    \u001b[34melse\u001b[39;49;00m:\r\n",
      "        kvstore = \u001b[33m'\u001b[39;49;00m\u001b[33mdist_device_sync\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m num_gpus > \u001b[34m0\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mdist_sync\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\r\n",
      "    trainer = gluon.Trainer(net.collect_params(), \u001b[33m'\u001b[39;49;00m\u001b[33msgd\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                            {\u001b[33m'\u001b[39;49;00m\u001b[33mlearning_rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: learning_rate, \u001b[33m'\u001b[39;49;00m\u001b[33mmomentum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: momentum},\r\n",
      "                            kvstore=kvstore)\r\n",
      "    metric = mx.metric.Accuracy()\r\n",
      "    loss = gluon.loss.SoftmaxCrossEntropyLoss()\r\n",
      "\r\n",
      "    \u001b[37m# shard the training data in case we are doing distributed training. Alternatively to splitting in memory,\u001b[39;49;00m\r\n",
      "    \u001b[37m# the data could be pre-split in S3 and use ShardedByS3Key to do distributed training.\u001b[39;49;00m\r\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(hosts) > \u001b[34m1\u001b[39;49;00m:\r\n",
      "        train_data = [x \u001b[34mfor\u001b[39;49;00m x \u001b[35min\u001b[39;49;00m train_data]\r\n",
      "        shard_size = \u001b[36mlen\u001b[39;49;00m(train_data) // \u001b[36mlen\u001b[39;49;00m(hosts)\r\n",
      "        \u001b[34mfor\u001b[39;49;00m i, host \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(hosts):\r\n",
      "            \u001b[34mif\u001b[39;49;00m host == current_host:\r\n",
      "                start = shard_size * i\r\n",
      "                end = start + shard_size\r\n",
      "                \u001b[34mbreak\u001b[39;49;00m\r\n",
      "\r\n",
      "        train_data = train_data[start:end]\r\n",
      "\r\n",
      "    net.hybridize()\r\n",
      "\r\n",
      "    best_val_score = \u001b[34m0.0\u001b[39;49;00m\r\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(epochs):\r\n",
      "        \u001b[37m# reset data iterator and metric at begining of epoch.\u001b[39;49;00m\r\n",
      "        metric.reset()\r\n",
      "        btic = time.time()\r\n",
      "        \u001b[34mfor\u001b[39;49;00m i, (data, label) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(train_data):\r\n",
      "            \u001b[37m# Copy data to ctx if necessary\u001b[39;49;00m\r\n",
      "            data = data.as_in_context(ctx)\r\n",
      "            label = label.as_in_context(ctx)\r\n",
      "            \u001b[37m# Start recording computation graph with record() section.\u001b[39;49;00m\r\n",
      "            \u001b[37m# Recorded graphs can then be differentiated with backward.\u001b[39;49;00m\r\n",
      "            \u001b[34mwith\u001b[39;49;00m autograd.record():\r\n",
      "                output = net(data)\r\n",
      "                L = loss(output, label)\r\n",
      "                L.backward()\r\n",
      "            \u001b[37m# take a gradient step with batch_size equal to data.shape[0]\u001b[39;49;00m\r\n",
      "            trainer.step(data.shape[\u001b[34m0\u001b[39;49;00m])\r\n",
      "            \u001b[37m# update metric at last.\u001b[39;49;00m\r\n",
      "            metric.update([label], [output])\r\n",
      "\r\n",
      "            \u001b[34mif\u001b[39;49;00m i % log_interval == \u001b[34m0\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m i > \u001b[34m0\u001b[39;49;00m:\r\n",
      "                name, acc = metric.get()\r\n",
      "                \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m[Epoch \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m Batch \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m] Training: \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m=\u001b[39;49;00m\u001b[33m%f\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m%f\u001b[39;49;00m\u001b[33m samples/s\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m %\r\n",
      "                      (epoch, i, name, acc, batch_size / (time.time() - btic)))\r\n",
      "\r\n",
      "            btic = time.time()\r\n",
      "\r\n",
      "        name, acc = metric.get()\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m[Epoch \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m] Training: \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m=\u001b[39;49;00m\u001b[33m%f\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m % (epoch, name, acc))\r\n",
      "\r\n",
      "        name, val_acc = test(ctx, net, val_data)\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m[Epoch \u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m] Validation: \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m=\u001b[39;49;00m\u001b[33m%f\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m % (epoch, name, val_acc))\r\n",
      "        \u001b[37m# checkpoint the model, params and optimizer states in the folder /opt/ml/checkpoints\u001b[39;49;00m\r\n",
      "        \u001b[34mif\u001b[39;49;00m checkpoints_enabled \u001b[35mand\u001b[39;49;00m val_acc > best_val_score:\r\n",
      "            best_val_score = val_acc\r\n",
      "            logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mSaving the model, params and optimizer state.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "            net.export(CHECKPOINTS_DIR + \u001b[33m\"\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m%.4f\u001b[39;49;00m\u001b[33m-gluon_mnist\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m%(best_val_score), epoch)\r\n",
      "            trainer.save_states(CHECKPOINTS_DIR + \u001b[33m'\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m%.4f\u001b[39;49;00m\u001b[33m-gluon_mnist-\u001b[39;49;00m\u001b[33m%d\u001b[39;49;00m\u001b[33m.states\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m%(best_val_score, epoch))\r\n",
      "\r\n",
      "    \u001b[34mif\u001b[39;49;00m current_host == hosts[\u001b[34m0\u001b[39;49;00m]:\r\n",
      "        save(net, model_dir)\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msave\u001b[39;49;00m(net, model_dir):\r\n",
      "    \u001b[37m# save the model\u001b[39;49;00m\r\n",
      "    net.export(\u001b[33m'\u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m/model\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m% model_dir)\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mdefine_network\u001b[39;49;00m():\r\n",
      "    net = nn.HybridSequential()\r\n",
      "    \u001b[34mwith\u001b[39;49;00m net.name_scope():\r\n",
      "        net.add(nn.Dense(\u001b[34m128\u001b[39;49;00m, activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "        net.add(nn.Dense(\u001b[34m64\u001b[39;49;00m, activation=\u001b[33m'\u001b[39;49;00m\u001b[33mrelu\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "        net.add(nn.Dense(\u001b[34m10\u001b[39;49;00m))\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m net\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtest\u001b[39;49;00m(ctx, net, val_data):\r\n",
      "    metric = mx.metric.Accuracy()\r\n",
      "    \u001b[34mfor\u001b[39;49;00m data, label \u001b[35min\u001b[39;49;00m val_data:\r\n",
      "        data = data.as_in_context(ctx)\r\n",
      "        label = label.as_in_context(ctx)\r\n",
      "        output = net(data)\r\n",
      "        metric.update([label], [output])\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m metric.get()\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\u001b[37m# ------------------------------------------------------------ #\u001b[39;49;00m\r\n",
      "\u001b[37m# Training execution                                           #\u001b[39;49;00m\r\n",
      "\u001b[37m# ------------------------------------------------------------ #\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--learning-rate\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.1\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.9\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--log-interval\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m100\u001b[39;49;00m)\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--train\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TESTING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mlist\u001b[39;49;00m, default=json.loads(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_args()\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    args = parse_args()\r\n",
      "    train(args)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize 'code/train.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyperparameters\n",
    "\n",
    "In addition, MXNet estimator allows you to parse command line arguments\n",
    "to your training script via `hyperparameters`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set local_mode to be True if you want to run the training script\n",
    "# on the machine that runs this notebook\n",
    "\n",
    "local_mode=True\n",
    "\n",
    "if local_mode:\n",
    "    instance_type='local'\n",
    "else:\n",
    "    instance_type='ml.c4.xlarge'\n",
    "    \n",
    "est = MXNet(\n",
    "    entry_point='train.py',\n",
    "    source_dir='code', # directory of your training script\n",
    "    role=role,\n",
    "    framework_version='1.7.0',\n",
    "    py_version='py3',\n",
    "    instance_type=instance_type,\n",
    "    instance_count=1,\n",
    "    output_path=output_path,\n",
    "    hyperparameters={\n",
    "        'batch-size':100,\n",
    "        'epochs':20,\n",
    "        'learning-rate': 0.1,\n",
    "        'momentum': 0.9,\n",
    "        'log-interval':100\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training container executes your training script like\n",
    "\n",
    "```\n",
    "python train.py --batch-size 100 --epochs 20 --learning-rate 0.1\n",
    "    --momentum 0.9 --log-interval 100\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up channels for training and testing data\n",
    "\n",
    "You need to tell `MXNet` estimator where to find your training and \n",
    "testing data. It can be a link to an S3 bucket or it can be a path\n",
    "in your local file system if you use local mode. In this example,\n",
    "we download the MNIST data from a public S3 bucket and upload it \n",
    "to your default bucket. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "region_name=sess.boto_region_name\n",
    "\n",
    "# Download training and testing data from a public S3 bucket\n",
    "def download_from_s3(data_dir='/tmp/data', train=True):\n",
    "    \"\"\"Download MNIST dataset and convert it to numpy array\n",
    "    \n",
    "    Args:\n",
    "        data_dir (str): directory to save the data\n",
    "        train (bool): download training set\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    if train:\n",
    "        images_file = \"train-images-idx3-ubyte.gz\"\n",
    "        labels_file = \"train-labels-idx1-ubyte.gz\"\n",
    "    else:\n",
    "        images_file = \"t10k-images-idx3-ubyte.gz\"\n",
    "        labels_file = \"t10k-labels-idx1-ubyte.gz\"\n",
    "\n",
    "    # download objects\n",
    "    s3 = boto3.client('s3')\n",
    "    bucket = \"sagemaker-sample-files\"\n",
    "    for obj in [images_file, labels_file]:\n",
    "        key = os.path.join(\"datasets/image/MNIST\", obj)\n",
    "        dest = os.path.join(data_dir, obj)\n",
    "        if not os.path.exists(dest):\n",
    "            s3.download_file(bucket, key, dest)\n",
    "    return\n",
    "\n",
    "\n",
    "download_from_s3('/tmp/data', True)\n",
    "download_from_s3('/tmp/data', False)\n",
    "\n",
    "\n",
    "def upload_file(file_name, bucket, object_name=None):\n",
    "    \"\"\"Upload a file to an S3 bucket\n",
    "\n",
    "    Args:\n",
    "        file_name (str): File to upload\n",
    "        bucket (str): Bucket to upload to\n",
    "        object_name (str): S3 object name. If not specified then file_name is used\n",
    "        \n",
    "    Return:\n",
    "        True if file was uploaded, else False\n",
    "    \"\"\"\n",
    "\n",
    "    # If S3 object_name was not specified, use file_name\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "\n",
    "    # Upload the file\n",
    "    s3_client = boto3.client('s3')\n",
    "    try:\n",
    "        response = s3_client.upload_file(file_name, bucket, object_name)\n",
    "    except ClientError as e:\n",
    "        logging.error(e)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "mnist_data = [\n",
    "    \"train-images-idx3-ubyte.gz\",\n",
    "    \"train-labels-idx1-ubyte.gz\",\n",
    "    \"t10k-images-idx3-ubyte.gz\", \n",
    "    \"t10k-labels-idx1-ubyte.gz\"\n",
    "]\n",
    "\n",
    "for f in mnist_data:\n",
    "    fpath = os.path.join('/tmp/data', f)\n",
    "    dest = os.path.join('mxnet/mnist', f)\n",
    "    upload_file(fpath, sess.default_bucket(), dest)\n",
    "    \n",
    "    \n",
    "# set up channels for training and testing data\n",
    "train_data_loc = \"s3://\" + sess.default_bucket() + '/mxnet/mnist'\n",
    "test_data_loc = \"s3://\" + sess.default_bucket() + '/mxnet/mnist'\n",
    "\n",
    "channels={\n",
    "    'training': train_data_loc,\n",
    "    'testing': test_data_loc\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keys of the dictionary `channels` are parsed to the training image\n",
    "and it creates the environment variable `SM_CHANNEL_<key name>`. \n",
    "\n",
    "In this example, `SM_CHANNEL_TRAINING` and `SM_CHANNEL_TESTING` are created in the training image (checkout \n",
    "how `code/train.py` access these variables). For more information,\n",
    "see: [SM_CHANNEL_{channel_name}](https://github.com/aws/sagemaker-training-toolkit/blob/master/ENVIRONMENT_VARIABLES.md#sm_channel_channel_name)\n",
    "\n",
    "If you want, you can create a channel for validation:\n",
    "```\n",
    "channels = {\n",
    "    'training': train_data_loc,\n",
    "    'validation': val_data_loc,\n",
    "    'test': test_data_loc\n",
    "    }\n",
    "```\n",
    "You can then access this channel within your training script via\n",
    "`SM_CHANNEL_VALIDATION`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the training script on SageMaker\n",
    "Now, the training container has everything to execute your training\n",
    "script. You can start the container by calling `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-19 00:50:18 Starting - Starting the training job...\n",
      "2020-11-19 00:50:21 Starting - Launching requested ML instances......\n",
      "2020-11-19 00:51:48 Starting - Preparing the instances for training......\n",
      "2020-11-19 00:52:36 Downloading - Downloading input data...\n",
      "2020-11-19 00:53:08 Training - Downloading the training image..\u001b[34m2020-11-19 00:53:23,688 sagemaker-training-toolkit INFO     Imported framework sagemaker_mxnet_container.training\u001b[0m\n",
      "\u001b[34m2020-11-19 00:53:23,690 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-19 00:53:23,702 sagemaker_mxnet_container.training INFO     MXNet training environment: {'SM_HOSTS': '[\"algo-1\"]', 'SM_NETWORK_INTERFACE_NAME': 'eth0', 'SM_HPS': '{\"batch-size\":100,\"epochs\":1,\"learning-rate\":0.1,\"log-interval\":100,\"momentum\":0.9}', 'SM_USER_ENTRY_POINT': 'train.py', 'SM_FRAMEWORK_PARAMS': '{}', 'SM_RESOURCE_CONFIG': '{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}', 'SM_INPUT_DATA_CONFIG': '{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}', 'SM_OUTPUT_DATA_DIR': '/opt/ml/output/data', 'SM_CHANNELS': '[\"testing\",\"training\"]', 'SM_CURRENT_HOST': 'algo-1', 'SM_MODULE_NAME': 'train', 'SM_LOG_LEVEL': '20', 'SM_FRAMEWORK_MODULE': 'sagemaker_mxnet_container.training:main', 'SM_INPUT_DIR': '/opt/ml/input', 'SM_INPUT_CONFIG_DIR': '/opt/ml/input/config', 'SM_OUTPUT_DIR': '/opt/ml/output', 'SM_NUM_CPUS': '4', 'SM_NUM_GPUS': '0', 'SM_MODEL_DIR': '/opt/ml/model', 'SM_MODULE_DIR': 's3://sagemaker-us-west-2-688520471316/mxnet-training-2020-11-19-00-50-17-998/source/sourcedir.tar.gz', 'SM_TRAINING_ENV': '{\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":100,\"epochs\":1,\"learning-rate\":0.1,\"log-interval\":100,\"momentum\":0.9},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-11-19-00-50-17-998\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/mxnet-training-2020-11-19-00-50-17-998/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}', 'SM_USER_ARGS': '[\"--batch-size\",\"100\",\"--epochs\",\"1\",\"--learning-rate\",\"0.1\",\"--log-interval\",\"100\",\"--momentum\",\"0.9\"]', 'SM_OUTPUT_INTERMEDIATE_DIR': '/opt/ml/output/intermediate', 'SM_CHANNEL_TESTING': '/opt/ml/input/data/testing', 'SM_CHANNEL_TRAINING': '/opt/ml/input/data/training', 'SM_HP_BATCH-SIZE': '100', 'SM_HP_LOG-INTERVAL': '100', 'SM_HP_LEARNING-RATE': '0.1', 'SM_HP_EPOCHS': '1', 'SM_HP_MOMENTUM': '0.9'}\u001b[0m\n",
      "\u001b[34m2020-11-19 00:53:24,201 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-19 00:53:27,265 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-19 00:53:27,279 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-11-19 00:53:27,290 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"testing\": \"/opt/ml/input/data/testing\",\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_mxnet_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 100,\n",
      "        \"log-interval\": 100,\n",
      "        \"learning-rate\": 0.1,\n",
      "        \"epochs\": 1,\n",
      "        \"momentum\": 0.9\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"testing\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"mxnet-training-2020-11-19-00-50-17-998\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-688520471316/mxnet-training-2020-11-19-00-50-17-998/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":100,\"epochs\":1,\"learning-rate\":0.1,\"log-interval\":100,\"momentum\":0.9}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"testing\",\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_mxnet_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-688520471316/mxnet-training-2020-11-19-00-50-17-998/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"testing\":\"/opt/ml/input/data/testing\",\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_mxnet_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":100,\"epochs\":1,\"learning-rate\":0.1,\"log-interval\":100,\"momentum\":0.9},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"testing\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"mxnet-training-2020-11-19-00-50-17-998\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-688520471316/mxnet-training-2020-11-19-00-50-17-998/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"100\",\"--epochs\",\"1\",\"--learning-rate\",\"0.1\",\"--log-interval\",\"100\",\"--momentum\",\"0.9\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TESTING=/opt/ml/input/data/testing\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=100\u001b[0m\n",
      "\u001b[34mSM_HP_LOG-INTERVAL=100\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.1\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mSM_HP_MOMENTUM=0.9\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.6 train.py --batch-size 100 --epochs 1 --learning-rate 0.1 --log-interval 100 --momentum 0.9\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-11-19 00:53:31.389 ip-10-0-208-1.us-west-2.compute.internal:17 INFO json_config.py:90] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2020-11-19 00:53:31.390 ip-10-0-208-1.us-west-2.compute.internal:17 INFO hook.py:193] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2020-11-19 00:53:31.390 ip-10-0-208-1.us-west-2.compute.internal:17 INFO hook.py:238] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2020-11-19 00:53:31.390 ip-10-0-208-1.us-west-2.compute.internal:17 INFO state_store.py:67] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2020-11-19 00:53:31.433 ip-10-0-208-1.us-west-2.compute.internal:17 INFO hook.py:398] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2020-11-19 00:53:31.433 ip-10-0-208-1.us-west-2.compute.internal:17 INFO hook.py:459] Hook is writing from the hook with pid: 17\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-11-19 00:53:31.445 ip-10-0-208-1.us-west-2.compute.internal:17 INFO hook.py:235] Registering hook for block softmaxcrossentropyloss0\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='softmaxcrossentropyloss0_output_0_GLOBAL',Value=2.327127456665039,Timestamp=1605747211.5122824,IterationNumber=0)\u001b[0m\n",
      "\u001b[34mDEBUG:root:metrics_file_path=/opt/ml/output/metrics/sagemaker/17.json\u001b[0m\n",
      "\u001b[34m[Epoch 0 Batch 100] Training: accuracy=0.791386, 25895.560906 samples/s\u001b[0m\n",
      "\u001b[34m[Epoch 0 Batch 200] Training: accuracy=0.854428, 27101.990178 samples/s\u001b[0m\n",
      "\u001b[34m[Epoch 0 Batch 300] Training: accuracy=0.882924, 26647.420584 samples/s\u001b[0m\n",
      "\u001b[34m[Epoch 0 Batch 400] Training: accuracy=0.897756, 26016.027788 samples/s\u001b[0m\n",
      "\u001b[34m[Epoch 0 Batch 500] Training: accuracy=0.908164, 17054.175815 samples/s\u001b[0m\n",
      "\u001b[34mDEBUG:root:Writing metric: _RawMetricData(MetricName='softmaxcrossentropyloss0_output_0_GLOBAL',Value=0.09875991940498352,Timestamp=1605747213.5652258,IterationNumber=500)\u001b[0m\n",
      "\u001b[34m[Epoch 0] Training: accuracy=0.915683\u001b[0m\n",
      "\u001b[34m[Epoch 0] Validation: accuracy=0.963717\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-11-19 00:53:46 Uploading - Uploading generated training model\n",
      "2020-11-19 00:53:46 Completed - Training job completed\n",
      "\u001b[34m2020-11-19 00:53:35,688 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 70\n",
      "Billable seconds: 70\n"
     ]
    }
   ],
   "source": [
    "est.fit(inputs=channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect and store model data\n",
    "\n",
    "Now, the training is finished, the model artifact has been saved in \n",
    "the `output_path`. We "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = est.model_data\n",
    "print(\"Model artifact saved at:\\n\", model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will store the variable `model_data` in the current notebook kernel. \n",
    "In the [next notebook](get_started_with_mnist_deploy.ipynb), you will learn how to retrieve the model artifact and deploy to a SageMaker\n",
    "Endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test and debug the entry point before executing the training container\n",
    "\n",
    "The entry point `code/train.py` provided here has been tested and it can be executed in the training container. \n",
    "When you do develop your own training script, it is a good practice to simulate the container environment \n",
    "in the local shell and test it before sending it to SageMaker, because debugging in a containerized environment\n",
    "is rather cumbersome. The following script shows how you can test your training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize code/test_train.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
